ê¸°ì¡´ í”„ë¡œì íŠ¸ì— ì¶”ê°€í•  í”„ë¡œì íŠ¸ì˜ PRD ë¥¼ ë§Œë“¤ì–´ ì¤˜.  
ë‚˜ì¤‘ì— í•©ì¹ ê±°ì•¼
ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ê°œì¸ ìƒìš©í™” ê°€ëŠ¥í•œ ì˜¤í”ˆì†ŒìŠ¤ë‚´ì—ì„œ ë§Œë“¤ì–´ ì¤˜

í˜„ì¬ê¹Œì§„ 
{
  "name": "the-canvas",
  "version": "0.1.0",
  "private": true,
  "scripts": {
    "dev": "next dev",
    "build": "next build",
    "start": "next start",
    "lint": "next lint"
  },
  "dependencies": {
    "@aws-sdk/client-s3": "^3.919.0",
    "@aws-sdk/s3-request-presigner": "^3.919.0",
    "@ffmpeg/ffmpeg": "^0.12.15",
    "@ffmpeg/util": "^0.12.2",
    "@radix-ui/react-avatar": "^1.1.0",
    "@radix-ui/react-dialog": "^1.1.1",
    "@radix-ui/react-dropdown-menu": "^2.1.1",
    "@radix-ui/react-label": "^2.1.0",
    "@radix-ui/react-progress": "^1.1.7",
    "@radix-ui/react-scroll-area": "^1.1.0",
    "@radix-ui/react-separator": "^1.1.0",
    "@radix-ui/react-slider": "^1.2.0",
    "@radix-ui/react-slot": "^1.1.0",
    "@radix-ui/react-toast": "^1.2.15",
    "@radix-ui/react-tooltip": "^1.1.2",
    "@univerjs/core": "^0.10.13",
    "@univerjs/design": "^0.10.13",
    "@univerjs/docs": "^0.10.13",
    "@univerjs/docs-ui": "^0.10.13",
    "@univerjs/engine-formula": "^0.10.13",
    "@univerjs/engine-render": "^0.10.13",
    "@univerjs/preset-sheets-core": "^0.10.13",
    "@univerjs/presets": "^0.10.13",
    "@univerjs/sheets": "^0.10.13",
    "@univerjs/sheets-formula": "^0.10.13",
    "@univerjs/sheets-ui": "^0.10.13",
    "@univerjs/ui": "^0.10.13",
    "class-variance-authority": "^0.7.0",
    "clsx": "^2.1.1",
    "date-fns": "^3.6.0",
    "fabric": "5.3.0-browser",
    "lodash.debounce": "^4.0.8",
    "lucide-react": "^0.399.0",
    "material-colors": "^1.2.6",
    "next": "^15.1.6",
    "next-themes": "^0.3.0",
    "react": "^19.0.0",
    "react-color": "^2.19.3",
    "react-dom": "^19.0.0",
    "react-icons": "^5.2.1",
    "react-use": "^17.5.0",
    "sonner": "^1.5.0",
    "tailwind-merge": "^2.3.0",
    "tailwindcss-animate": "^1.0.7",
    "use-file-picker": "^2.1.4",
    "uuidv4": "^6.2.13",
    "zustand": "^4.5.4"
  },
  "devDependencies": {
    "@types/fabric": "5.3.0",
    "@types/lodash.debounce": "^4.0.9",
    "@types/material-colors": "^1.2.3",
    "@types/node": "^20",
    "@types/react": "^19",
    "@types/react-color": "^3.0.12",
    "@types/react-dom": "^19",
    "eslint": "^8",
    "eslint-config-next": "^15.1.6",
    "jsdom": "^27.0.1",
    "postcss": "^8",
    "tailwindcss": "^3.4.1",
    "typescript": "^5"
  }
}
ì˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì¼ì–´, ì¶”ê°€ëŠ” ë‹¹ì—² ê°€ëŠ¥í•˜ê³  ë³€ê²½ì€ ê¸°ì¡´ í”„ë¡œì íŠ¸ë„ ê³ ë ¤í•´ì•¼ í•´
ì €ì¥ì†ŒëŠ” AWS S3ë¥¼ ì‚¬ìš©í•˜ê³  ìˆì–´, ffmpeg ë¡œ ì˜ìƒ í•©ì¹˜ë©´ ì¢‹ì„ë“¯ í•´

<í”„ë¡œì íŠ¸ ì„¤ëª…>
1. ì´ë¯¸ì§€ì™€ ë™ì˜ìƒ ìƒì„±ê¸°
   1) ì´ë¯¸ì§€ ìƒì„±ê¸° : 
       ë‚˜ë…¸ë°”ë‚˜ë‚˜ ì´ë¯¸ì§€ ë§Œë“¤ê¸° ( ì œë¯¸ë‚˜ì´ flash 2.5 ì´ë¯¸ì§€ ìƒì„± )
       êµ¬ê¸€ ai studio ì—ì„œ ì´ë¯¸ì§€ ë§Œë“œëŠ” ìƒ˜í”Œ ì›¹ì•±ê³¼ ìœ ì‚¬í•˜ê²Œ ë§Œë“¤ì–´ ì´ë¯¸ì§€ ìƒì„±
   2) ë™ì˜ìƒ ìƒì„±ê¸°
       ë‚˜ë…¸ë°”ë‚˜ë‚˜ì—ì„œ ìƒì„±í•œ ì´ë¯¸ì§€ê°€ 1ì¥ì´ë‚˜ 2ì¥ì´ë‚˜ í•„ìš”í•œë°
       ìˆì¸ ë¥¼ ìœ„í•œ ìƒì„± : ë™ì˜ìƒ ì‹œì‘ìš©/ëìš© ì´ë¯¸ì§€ë¥¼ ë‹¤ë¥´ê²Œ ë„£ìœ¼ë©´ 
       ê²Œì„ì„ ìœ„í•œ ìƒì„± : ë™ì˜ìƒ ì‹œì‘ìš©/ëìš© ì´ë¯¸ì§€ë¥¼ ê°™ê²Œ ë„£ìœ¼ë©´

--> ë” ì„¸ë°€í•œ ë‚´ìš©ì€ ë¬¸ì„œ ì²¨ë¶€ ---


2. ìˆì¸  ìƒì„±ê¸° 
   Mp4 ê°€ ì—¬ëŸ¬ê°œ ìˆëŠ”ë° canva ì˜ ë™ì˜ìƒ í¸ì§‘ê¸°ì²˜ëŸ¼ ì—°ê²°ì‹œì¼œì„œ í•˜ë‚˜ì˜ ì˜ìƒìœ¼ë¡œ ë§Œë“¤ìˆ˜ ìˆì–´ì•¼ í•¨
   1) ì˜ìƒê°„ ì—¬ëŸ¬ê°€ì§€ íŠ¸ìœˆ ê¸°ëŠ¥ ì‚½ì… ê°€ëŠ¥( ì˜ìƒ í˜ì´ë“œ ì „í™˜ë“± )í•œ íˆ´(UI)
   2) "fabric": "5.3.0-browser", ë¡œ ì—¬ëŸ¬ ì´ë¯¸ì§€, ê¸€ìë“¤ì„ ìº”ë²„ìŠ¤ ìœ„ì— ê·¸ë¦¬ê³  
      ê·¸ fabric ìš”ì†Œë“¤ì˜ íŠ¸ìœˆì„ í¸ì§‘í•  ìˆ˜ ìˆëŠ” íˆ´(UI)
   3) ìë§‰ ìƒì„±ê¸° ( ìë§‰ ì½ì–´ì£¼ê¸°, ë‹¤êµ­ì–´ê°€ ê°€ëŠ¥í•´ì•¼ í•¨ ), íš¨ê³¼ìŒ ì‚½ì…ê¸°, ë°°ê²½ìŒì•… ì‚½ì…ê¸°

   ì˜ìƒìœ„ì— fabricì˜ íŠ¸ìœˆì„ í¸ì§‘í•œ canvas í™”ë©´ì´ ìœ„ì¹˜í•˜ê³  
   ì˜ìƒ í”„ë ˆì„ì‚¬ì´ì— ìŒì„± ì¶”ê°€í•˜ê¸°/ë°°ê²½ìŒì•… ë°”ê¾¸ê¸° ë“±ì„ í•˜ê³  
   ë§ˆì§€ë§‰ì— ìƒì„± ëˆ„ë¥´ë©´ 
   ì˜ìƒë“¤ê³¼ canvas(fabricë“¤ì´ ë“¤ì–´ê°„)ê³¼ ìë§‰, ìŒì„±, ë°°ê²½ìŒì•…ì´ í•©ì³ì§„ 1ê°œì˜ ì˜ìƒì´ ë‚˜ì™€ì•¼ í•´
   í¸ì§‘í•˜ë©´ì„œ ë§ˆì§€ë§‰ ìƒì„± ì „ì— ì‹œê°„ì— ë”°ë¼ í”Œë ˆì´ë¥¼ í•´ ë³¼ìˆ˜ ìˆì–´ì•¼ í•´
  

--------- ë‹ˆê°€ ì°¸ì¡°í–ˆìœ¼ë©´ í•˜ëŠ” ë‚´ìš©ë“¤ -------------------
# ğŸ¬ AI ìºë¦­í„° ìˆì¸  ì œì‘ ì‹œìŠ¤í…œ - ì™„ë²½ ê°€ì´ë“œ

## ğŸ“‹ ëª©ì°¨
1. [ê°œìš”](#ê°œìš”)
2. [ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜](#ì‹œìŠ¤í…œ-ì•„í‚¤í…ì²˜)
3. [Backend êµ¬í˜„](#backend-êµ¬í˜„)
4. [Frontend êµ¬í˜„](#frontend-êµ¬í˜„)
5. [ComfyUI ì„¤ì •](#comfyui-ì„¤ì •)
6. [ì„¤ì¹˜ ë° ì‹¤í–‰](#ì„¤ì¹˜-ë°-ì‹¤í–‰)
7. [ì‚¬ìš© ê°€ì´ë“œ](#ì‚¬ìš©-ê°€ì´ë“œ)
8. [íŠ¸ëŸ¬ë¸”ìŠˆíŒ…](#íŠ¸ëŸ¬ë¸”ìŠˆíŒ…)

## ê°œìš”

Googleì˜ Gemini 2.5 Flash Image (ë‚˜ë…¸ ë°”ë‚˜ë‚˜)ì™€ Stable Video Diffusionì„ í™œìš©í•˜ì—¬ ì¼ê´€ëœ ìºë¦­í„°ë¡œ ìˆì¸  ì˜ìƒì„ ì œì‘í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

### í•µì‹¬ ê¸°ëŠ¥
- âœ¨ **ìºë¦­í„° ì¼ê´€ì„±**: ë™ì¼ ìºë¦­í„° ìœ ì§€
- ğŸ‘— **ë¶€ë¶„ êµì²´**: ì˜ìƒ, í—¤ì–´, ì†Œí’ˆ ë³€ê²½
- ğŸ­ **í¬ì¦ˆ ë³€ê²½**: ì°¸ì¡° ì´ë¯¸ì§€ë¡œ í¬ì¦ˆ ì ìš©
- ğŸ¬ **ë¹„ë””ì˜¤ ìƒì„±**: ì´ë¯¸ì§€â†’ë¹„ë””ì˜¤ ë³€í™˜
- ğŸ”„ **ë£¨í”„ ì• ë‹ˆë©”ì´ì…˜**: ê²Œì„ ìºë¦­í„°ìš©
- ğŸ—£ï¸ **ìŒì„± ì‚½ì…**: TTS ìë§‰ ìŒì„±

## ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Next.js 15 UI  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FastAPI Server â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â†“             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Nano Banana  â”‚  â”‚  ComfyUI +   â”‚
â”‚   (Gemini)   â”‚  â”‚     SVD      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Backend êµ¬í˜„

### ë©”ì¸ ì„œë²„ (main.py)
```python
# backend/main.py
from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional
import google.generativeai as genai
import os
import base64
import json
import asyncio
from pathlib import Path
import uuid

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# Gemini ì„¤ì •
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
nano_banana = genai.GenerativeModel("gemini-2-5-flash-image")

class CharacterConfig(BaseModel):
    """ìºë¦­í„° ì„¤ì •"""
    name: str
    base_description: str
    reference_image: Optional[str] = None  # base64 ì´ë¯¸ì§€
    
class SceneRequest(BaseModel):
    """ì¥ë©´ ìƒì„± ìš”ì²­"""
    character: CharacterConfig
    scenes: List[dict]  # ê° ì¥ë©´ ì •ë³´
    video_type: str = "story"  # "story" or "loop"
    fps: int = 8
    frames: int = 25
    
class CharacterSession:
    """ìºë¦­í„° ì¼ê´€ì„± ìœ ì§€ë¥¼ ìœ„í•œ ì„¸ì…˜"""
    def __init__(self, character: CharacterConfig):
        self.character = character
        self.reference_images = []
        self.generated_images = []
        
    async def generate_consistent_image(self, 
        action: str,
        angle: Optional[str] = None,
        outfit: Optional[str] = None,
        props: Optional[str] = None,
        background: Optional[str] = None,
        pose_reference: Optional[str] = None
    ):
        """ì¼ê´€ëœ ìºë¦­í„°ë¡œ ì´ë¯¸ì§€ ìƒì„±"""
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt_parts = []
        
        # ê¸°ë³¸ ìºë¦­í„° ì„¤ëª…
        prompt_parts.append(f"Character: {self.character.base_description}")
        
        # ë™ì‘
        if action:
            prompt_parts.append(f"Action: {action}")
        
        # ê°ë„ ë³€ê²½
        if angle:
            prompt_parts.append(f"Camera angle: {angle}")
            
        # ì˜ìƒ ë³€ê²½
        if outfit:
            prompt_parts.append(f"Wearing: {outfit}")
            
        # ì†Œí’ˆ ì¶”ê°€
        if props:
            prompt_parts.append(f"Holding/Using: {props}")
            
        # ë°°ê²½ ì„¤ì •
        if background:
            prompt_parts.append(f"Background: {background}")
        else:
            prompt_parts.append("Clean white background for easy extraction")
            
        # ì¼ê´€ì„± ìœ ì§€ ì§€ì‹œ
        prompt_parts.append("IMPORTANT: Maintain exact same character appearance and features")
        
        full_prompt = "\n".join(prompt_parts)
        
        # ì´ë¯¸ì§€ ìƒì„±
        contents = [full_prompt]
        
        # ì°¸ì¡° ì´ë¯¸ì§€ ì¶”ê°€ (ìºë¦­í„° ì¼ê´€ì„±)
        if self.character.reference_image:
            contents.append(self._decode_base64_image(self.character.reference_image))
            
        # í¬ì¦ˆ ì°¸ì¡° ì´ë¯¸ì§€
        if pose_reference:
            contents.append(self._decode_base64_image(pose_reference))
            contents.append("Use this pose reference but keep the character's appearance")
            
        # ì´ì „ ìƒì„± ì´ë¯¸ì§€ë„ ì°¸ì¡° (ì¼ê´€ì„± ê°•í™”)
        if self.generated_images:
            contents.append(self.generated_images[-1])
            contents.append("Keep this exact character")
            
        response = nano_banana.generate_content(contents)
        
        # ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥
        for part in response.candidates[0].content.parts:
            if part.inline_data:
                image_data = part.inline_data.data
                self.generated_images.append(image_data)
                return base64.b64encode(image_data).decode()
                
        return None
    
    def _decode_base64_image(self, base64_str):
        """Base64 ì´ë¯¸ì§€ ë””ì½”ë”©"""
        from PIL import Image
        import io
        
        image_data = base64.b64decode(base64_str)
        return Image.open(io.BytesIO(image_data))

@app.post("/api/create-character-animation")
async def create_character_animation(request: SceneRequest):
    """ìºë¦­í„° ì• ë‹ˆë©”ì´ì…˜ ìƒì„± ì „ì²´ íŒŒì´í”„ë¼ì¸"""
    
    try:
        # 1. ìºë¦­í„° ì„¸ì…˜ ìƒì„±
        session = CharacterSession(request.character)
        
        # 2. ê° ì¥ë©´ë³„ ì´ë¯¸ì§€ ìƒì„±
        scene_images = []
        
        for i, scene in enumerate(request.scenes):
            print(f"ì¥ë©´ {i+1} ìƒì„± ì¤‘...")
            
            image_b64 = await session.generate_consistent_image(
                action=scene.get('action'),
                angle=scene.get('angle'),
                outfit=scene.get('outfit'),
                props=scene.get('props'),
                background=scene.get('background'),
                pose_reference=scene.get('pose_reference')
            )
            
            if image_b64:
                scene_images.append({
                    'scene_num': i + 1,
                    'image': image_b64,
                    'description': scene.get('action', '')
                })
        
        # 3. ë¹„ë””ì˜¤ íƒ€ì…ì— ë”°ë¥¸ ì²˜ë¦¬
        videos = []
        
        if request.video_type == "loop":
            # ê²Œì„ ìºë¦­í„° ë£¨í”„ ì• ë‹ˆë©”ì´ì…˜
            for i, scene_img in enumerate(scene_images):
                # ê°™ì€ ì´ë¯¸ì§€ë¡œ ì‹œì‘ê³¼ ë ì„¤ì • (ë£¨í”„)
                video_url = await generate_loop_animation(
                    start_image=scene_img['image'],
                    end_image=scene_img['image'],  # ê°™ì€ ì´ë¯¸ì§€
                    action=scene_img['description'],
                    fps=request.fps,
                    frames=request.frames
                )
                videos.append({
                    'scene': i + 1,
                    'video_url': video_url,
                    'type': 'loop'
                })
                
        else:  # story
            # ì—°ì†ëœ ìŠ¤í† ë¦¬ ì˜ìƒ
            for i in range(len(scene_images) - 1):
                video_url = await generate_story_video(
                    start_image=scene_images[i]['image'],
                    end_image=scene_images[i + 1]['image'],
                    fps=request.fps,
                    frames=request.frames
                )
                videos.append({
                    'scene': f"{i+1} to {i+2}",
                    'video_url': video_url,
                    'type': 'transition'
                })
        
        # 4. ìŒì„± ìƒì„± (ì˜µì…˜)
        audio_urls = []
        for scene in request.scenes:
            if scene.get('dialogue'):
                audio_url = await generate_audio(scene['dialogue'])
                audio_urls.append(audio_url)
        
        return {
            "success": True,
            "character_name": request.character.name,
            "images": scene_images,
            "videos": videos,
            "audio": audio_urls
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

async def generate_loop_animation(
    start_image: str, 
    end_image: str,
    action: str,
    fps: int,
    frames: int
) -> str:
    """ë£¨í”„ ì• ë‹ˆë©”ì´ì…˜ ìƒì„± (ComfyUI SVD)"""
    
    from comfyui_client import ComfyUIClient
    
    client = ComfyUIClient()
    
    # ComfyUI ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
    workflow = create_loop_workflow(action, fps, frames)
    
    # ì´ë¯¸ì§€ ì—…ë¡œë“œ
    start_path = await save_base64_image(start_image, "start")
    end_path = await save_base64_image(end_image, "end")
    
    await client.upload_image(start_path)
    await client.upload_image(end_path)
    
    # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
    prompt_id = await client.queue_prompt(workflow)
    video_path = await client.get_result(prompt_id)
    
    return f"http://localhost:8000/videos/{video_path}"

def create_loop_workflow(action: str, fps: int, frames: int):
    """ë£¨í”„ ì• ë‹ˆë©”ì´ì…˜ìš© ComfyUI ì›Œí¬í”Œë¡œìš°"""
    return {
        "1": {
            "class_type": "LoadImage",
            "inputs": {"image": "start.png"}
        },
        "2": {
            "class_type": "SVDimg2vid",
            "inputs": {
                "image": ["1", 0],
                "video_frames": frames,
                "motion_bucket_id": 50,  # ì‘ì€ ì›€ì§ì„
                "fps": fps,
                "augmentation_level": 0.1,
                "min_cfg": 1.0,
                "seed": 42,  # ì¼ê´€ì„±ì„ ìœ„í•´ ê³ ì •
                "motion_prompt": f"Character performing: {action}, then returning to original pose"
            }
        },
        "3": {
            "class_type": "VideoLoop",  # ì»¤ìŠ¤í…€ ë…¸ë“œ
            "inputs": {
                "video": ["2", 0],
                "blend_frames": 5  # ë¶€ë“œëŸ¬ìš´ ë£¨í”„ë¥¼ ìœ„í•œ ë¸”ë Œë”©
            }
        },
        "4": {
            "class_type": "SaveVideo",
            "inputs": {
                "video": ["3", 0],
                "filename_prefix": "loop_animation"
            }
        }
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

### ComfyUI í´ë¼ì´ì–¸íŠ¸
```python
# backend/comfyui_client.py
import aiohttp
import asyncio
import json
import uuid
from pathlib import Path

class ComfyUIClient:
    def __init__(self, server_address="http://127.0.0.1:8188"):
        self.server_address = server_address
        self.client_id = str(uuid.uuid4())
    
    async def upload_image(self, image_path: Path):
        """ì´ë¯¸ì§€ ì—…ë¡œë“œ"""
        async with aiohttp.ClientSession() as session:
            with open(image_path, 'rb') as f:
                data = aiohttp.FormData()
                data.add_field('image', f, 
                              filename=image_path.name)
                
                async with session.post(
                    f"{self.server_address}/upload/image",
                    data=data
                ) as response:
                    return await response.json()
    
    async def queue_prompt(self, workflow: dict):
        """ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
        async with aiohttp.ClientSession() as session:
            async with session.post(
                f"{self.server_address}/prompt",
                json={
                    "prompt": workflow,
                    "client_id": self.client_id
                }
            ) as response:
                result = await response.json()
                return result.get('prompt_id')
    
    async def get_result(self, prompt_id: str, timeout: int = 120):
        """ê²°ê³¼ ëŒ€ê¸° ë° ë°˜í™˜"""
        async with aiohttp.ClientSession() as session:
            start_time = asyncio.get_event_loop().time()
            
            while asyncio.get_event_loop().time() - start_time < timeout:
                async with session.get(
                    f"{self.server_address}/history/{prompt_id}"
                ) as response:
                    history = await response.json()
                    
                    if prompt_id in history:
                        outputs = history[prompt_id].get('outputs', {})
                        for node_id, node_output in outputs.items():
                            if 'videos' in node_output:
                                video = node_output['videos'][0]
                                return video['filename']
                
                await asyncio.sleep(1)
            
            raise TimeoutError(f"Result not ready after {timeout} seconds")
```

## Frontend êµ¬í˜„

### ë©”ì¸ í˜ì´ì§€
```typescript
// app/page.tsx
'use client';

import { useState } from 'react';
import CharacterCreator from '@/components/CharacterCreator';
import SceneBuilder from '@/components/SceneBuilder';
import VideoPreview from '@/components/VideoPreview';
import { Character, Scene, GeneratedContent } from '@/types';

export default function ShortsCreator() {
  const [character, setCharacter] = useState<Character | null>(null);
  const [scenes, setScenes] = useState<Scene[]>([]);
  const [generatedContent, setGeneratedContent] = useState<GeneratedContent | null>(null);
  const [loading, setLoading] = useState(false);
  const [videoType, setVideoType] = useState<'story' | 'loop'>('story');

  const handleGenerate = async () => {
    if (!character || scenes.length === 0) {
      alert('ìºë¦­í„°ì™€ ìµœì†Œ 1ê°œ ì´ìƒì˜ ì¥ë©´ì´ í•„ìš”í•©ë‹ˆë‹¤!');
      return;
    }

    setLoading(true);
    try {
      const response = await fetch('http://localhost:8000/api/create-character-animation', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          character,
          scenes,
          video_type: videoType,
          fps: 8,
          frames: 25
        })
      });

      const data = await response.json();
      setGeneratedContent(data);
    } catch (error) {
      console.error('ìƒì„± ì‹¤íŒ¨:', error);
      alert('ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
    } finally {
      setLoading(false);
    }
  };

  return (
    <div className="min-h-screen bg-gradient-to-br from-purple-50 to-pink-50">
      <div className="container mx-auto p-8">
        <h1 className="text-4xl font-bold mb-8 text-center">
          ğŸ¬ AI ìºë¦­í„° ìˆì¸  ì œì‘ê¸°
        </h1>

        <div className="grid grid-cols-1 lg:grid-cols-2 gap-8">
          {/* ì™¼ìª½: ìºë¦­í„° & ì¥ë©´ ì„¤ì • */}
          <div className="space-y-6">
            {/* ìºë¦­í„° ìƒì„± */}
            <div className="bg-white rounded-xl shadow-lg p-6">
              <h2 className="text-2xl font-semibold mb-4">
                ğŸ‘¤ ìºë¦­í„° ë§Œë“¤ê¸°
              </h2>
              <CharacterCreator 
                onCharacterCreate={setCharacter}
                character={character}
              />
            </div>

            {/* ì¥ë©´ ë¹Œë” */}
            <div className="bg-white rounded-xl shadow-lg p-6">
              <h2 className="text-2xl font-semibold mb-4">
                ğŸ­ ì¥ë©´ êµ¬ì„±í•˜ê¸°
              </h2>
              
              {/* ë¹„ë””ì˜¤ íƒ€ì… ì„ íƒ */}
              <div className="mb-4 flex gap-4">
                <button
                  onClick={() => setVideoType('story')}
                  className={`px-4 py-2 rounded-lg ${
                    videoType === 'story' 
                      ? 'bg-blue-500 text-white' 
                      : 'bg-gray-200'
                  }`}
                >
                  ğŸ“– ìŠ¤í† ë¦¬ ëª¨ë“œ
                </button>
                <button
                  onClick={() => setVideoType('loop')}
                  className={`px-4 py-2 rounded-lg ${
                    videoType === 'loop' 
                      ? 'bg-green-500 text-white' 
                      : 'bg-gray-200'
                  }`}
                >
                  ğŸ”„ ë£¨í”„ ì• ë‹ˆë©”ì´ì…˜
                </button>
              </div>

              <SceneBuilder 
                scenes={scenes}
                onScenesUpdate={setScenes}
                videoType={videoType}
              />
            </div>

            {/* ìƒì„± ë²„íŠ¼ */}
            <button
              onClick={handleGenerate}
              disabled={loading || !character || scenes.length === 0}
              className="w-full py-4 bg-gradient-to-r from-purple-500 to-pink-500 
                        text-white font-bold rounded-xl shadow-lg
                        disabled:opacity-50 disabled:cursor-not-allowed
                        hover:from-purple-600 hover:to-pink-600 transition"
            >
              {loading ? 'ğŸ”„ ìƒì„± ì¤‘...' : 'ğŸ¬ ìˆì¸  ë§Œë“¤ê¸°'}
            </button>
          </div>

          {/* ì˜¤ë¥¸ìª½: ë¯¸ë¦¬ë³´ê¸° */}
          <div className="bg-white rounded-xl shadow-lg p-6">
            <h2 className="text-2xl font-semibold mb-4">
              ğŸ“º ë¯¸ë¦¬ë³´ê¸°
            </h2>
            <VideoPreview content={generatedContent} loading={loading} />
          </div>
        </div>
      </div>
    </div>
  );
}
```

### íƒ€ì… ì •ì˜
```typescript
// types/index.ts
export interface Character {
  name: string;
  base_description: string;
  reference_image?: string | null;
}

export interface Scene {
  action: string;
  angle?: string;
  outfit?: string;
  props?: string;
  background?: string;
  pose_reference?: string;
  dialogue?: string;
}

export interface GeneratedContent {
  success: boolean;
  character_name: string;
  images: Array<{
    scene_num: number;
    image: string;
    description: string;
  }>;
  videos: Array<{
    scene: string | number;
    video_url: string;
    type: 'loop' | 'transition';
  }>;
  audio?: string[];
}
```

## ComfyUI ì„¤ì •

### í•„ìˆ˜ ì»¤ìŠ¤í…€ ë…¸ë“œ ì„¤ì¹˜
```bash
# ComfyUI ë””ë ‰í† ë¦¬ë¡œ ì´ë™
cd ComfyUI/custom_nodes

# ë‚˜ë…¸ë°”ë‚˜ë‚˜ ë…¸ë“œ (Gemini 2.5 Flash Image)
git clone https://github.com/ShmuelRonen/ComfyUI-NanoBanano.git

# SVD (Stable Video Diffusion) ë…¸ë“œ
git clone https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite.git

# ë¹„ë””ì˜¤ ë£¨í”„ ì²˜ë¦¬
git clone https://github.com/Fannovel16/ComfyUI-Video-Looping.git

# í”„ë ˆì„ ë³´ê°„
git clone https://github.com/Fannovel16/ComfyUI-Frame-Interpolation.git

# ê° ë…¸ë“œì˜ ì˜ì¡´ì„± ì„¤ì¹˜
cd ComfyUI-NanoBanano && pip install -r requirements.txt && cd ..
cd ComfyUI-VideoHelperSuite && pip install -r requirements.txt && cd ..
```

### SVD ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
```bash
# SVD ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
cd ComfyUI/models/checkpoints

# Hugging Faceì—ì„œ SVD ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
huggingface-cli download stabilityai/stable-video-diffusion-img2vid-xt \
  --local-dir ./svd_xt/
```

## ì„¤ì¹˜ ë° ì‹¤í–‰

### ì‚¬ì „ ìš”êµ¬ì‚¬í•­

- Python 3.10+
- Node.js 18+
- CUDA (GPU ê°€ì†, ì„ íƒì‚¬í•­)
- ìµœì†Œ 16GB RAM
- 20GB+ ì €ì¥ê³µê°„

### Step 1: í™˜ê²½ ì„¤ì •
```bash
# í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir character-shorts-creator
cd character-shorts-creator

# Python ê°€ìƒí™˜ê²½ ìƒì„±
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Google API í‚¤ ì„¤ì •
export GOOGLE_API_KEY="your-api-key-here"
```

### Step 2: Backend ì„¤ì¹˜
```bash
# Backend ë””ë ‰í† ë¦¬ ìƒì„±
mkdir backend
cd backend

# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install fastapi uvicorn google-generativeai aiohttp pillow gtts

# í™˜ê²½ë³€ìˆ˜ íŒŒì¼ ìƒì„±
echo "GOOGLE_API_KEY=your-api-key" > .env
```

### Step 3: Frontend ì„¤ì¹˜
```bash
# Frontend ìƒì„±
npx create-next-app@latest frontend --typescript --tailwind --app
cd frontend

# ì¶”ê°€ íŒ¨í‚¤ì§€ ì„¤ì¹˜
npm install axios react-dropzone
```

### Step 4: ì„œë¹„ìŠ¤ ì‹¤í–‰
```bash
# Terminal 1: ComfyUI ì‹¤í–‰
cd ComfyUI
python main.py --listen

# Terminal 2: Backend ì‹¤í–‰
cd backend
python main.py

# Terminal 3: Frontend ì‹¤í–‰
cd frontend
npm run dev
```

### Step 5: ì ‘ì†
```
ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:3000 ì ‘ì†
```

## ì‚¬ìš© ê°€ì´ë“œ

### ğŸ¨ ìºë¦­í„° ìƒì„±

1. **ìºë¦­í„° ì´ë¦„ ì…ë ¥**
   - ì˜ˆ: "ë‚˜ë‚˜", "ì² ìˆ˜", "ë¯¸ë¯¸"

2. **ìƒì„¸ ì„¤ëª… ì‘ì„±**
```
   ë¶„í™ìƒ‰ ê¸´ ë¨¸ë¦¬, í° íŒŒë€ ëˆˆ, ë°ì€ ë¯¸ì†Œ
   íŒŒë€ìƒ‰ ì›í”¼ìŠ¤, í°ìƒ‰ ìš´ë™í™”
   10ì‚´ ì •ë„ì˜ ê·€ì—¬ìš´ ì†Œë…€
```

3. **ì°¸ì¡° ì´ë¯¸ì§€ ì—…ë¡œë“œ** (ì„ íƒì‚¬í•­)
   - ìºë¦­í„° ì¼ê´€ì„± í–¥ìƒ
   - PNG/JPG í˜•ì‹ ì§€ì›

### ğŸ¬ ì¥ë©´ êµ¬ì„±

#### ìŠ¤í† ë¦¬ ëª¨ë“œ ì˜ˆì‹œ
```
ì¥ë©´ 1: ê±·ê¸° / ì •ë©´ / ê³µì› ë°°ê²½
ì¥ë©´ 2: ì¸ì‚¬í•˜ê¸° / ì¸¡ë©´ / "ì•ˆë…•í•˜ì„¸ìš”!"
ì¥ë©´ 3: ë›°ì–´ê°€ê¸° / ë’·ëª¨ìŠµ / í•™êµ ë°°ê²½
```

#### ë£¨í”„ ì• ë‹ˆë©”ì´ì…˜ ì˜ˆì‹œ
```
ê³µê²© ëª¨ì…˜ / ì •ë©´ / ë°°ê²½ ì—†ìŒ
ì í”„ ë™ì‘ / ì¸¡ë©´ / ê°„ë‹¨í•œ ë°°ê²½
ìŠ¹ë¦¬ í¬ì¦ˆ / 3/4 ê°ë„ / ì´í™íŠ¸ ì¶”ê°€
```

### ğŸ¯ ê³ ê¸‰ ê¸°ëŠ¥

#### ì˜ìƒ ë³€ê²½
```
ê¸°ë³¸: íŒŒë€ ì›í”¼ìŠ¤
ì¥ë©´ 2: ë¹¨ê°„ ë“œë ˆìŠ¤ë¡œ ë³€ê²½
ì¥ë©´ 3: ìš´ë™ë³µìœ¼ë¡œ ë³€ê²½
```

#### ì†Œí’ˆ ì¶”ê°€
```
ì¥ë©´ 1: ê½ƒë‹¤ë°œ ë“¤ê¸°
ì¥ë©´ 2: ìš°ì‚° ë“¤ê¸°
ì¥ë©´ 3: ê°€ë°© ë©”ê¸°
```

#### ì¹´ë©”ë¼ ì•µê¸€
- ì •ë©´, ì¸¡ë©´, ë’·ëª¨ìŠµ
- ìœ„ì—ì„œ, ì•„ë˜ì—ì„œ
- í´ë¡œì¦ˆì—…, ì „ì‹ ìƒ·
- 3/4 ê°ë„

### ğŸ’¾ ì¶œë ¥ í˜•ì‹

- **ì´ë¯¸ì§€**: PNG (1024x1024)
- **ë¹„ë””ì˜¤**: MP4 (8fps, 25frames)
- **ì˜¤ë””ì˜¤**: MP3 (TTS ìƒì„±)

## íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œ

#### 1. API í‚¤ ì˜¤ë¥˜
```bash
# í•´ê²°ë°©ë²•
export GOOGLE_API_KEY="ì˜¬ë°”ë¥¸-API-í‚¤"
# Google AI Studioì—ì„œ ìƒˆ í‚¤ ë°œê¸‰
```

#### 2. ComfyUI ì—°ê²° ì‹¤íŒ¨
```bash
# ComfyUIê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
curl http://localhost:8188
# í¬íŠ¸ ë³€ê²½ì´ í•„ìš”í•œ ê²½ìš°
python main.py --listen --port 8189
```

#### 3. ë©”ëª¨ë¦¬ ë¶€ì¡±
```python
# frames ìˆ˜ ì¤„ì´ê¸°
frames: int = 15  # 25 -> 15
# ì´ë¯¸ì§€ í•´ìƒë„ ë‚®ì¶”ê¸°
resolution: str = "512x512"  # 1024x1024 -> 512x512
```

#### 4. ìºë¦­í„° ì¼ê´€ì„± ë¬¸ì œ
- ì°¸ì¡° ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ
- ì„¤ëª…ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±
- seed ê°’ ê³ ì • ì‚¬ìš©

### ì„±ëŠ¥ ìµœì í™”

#### GPU ê°€ì† í™œì„±í™”
```bash
# CUDA ì„¤ì¹˜ í™•ì¸
nvidia-smi
# PyTorch GPU ë²„ì „ ì„¤ì¹˜
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

#### ë°°ì¹˜ ì²˜ë¦¬
```python
# ì—¬ëŸ¬ ì¥ë©´ ë™ì‹œ ìƒì„±
batch_size = 3
scenes = process_in_batches(scenes, batch_size)
```

#### ìºì‹± í™œìš©
```python
# ìƒì„±ëœ ì´ë¯¸ì§€ ìºì‹±
cache_dir = Path("cache")
if cache_dir.exists():
    return load_from_cache()
```

## í”„ë¡œì íŠ¸ êµ¬ì¡°
```
character-shorts-creator/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                 # FastAPI ë©”ì¸ ì„œë²„
â”‚   â”œâ”€â”€ comfyui_client.py       # ComfyUI í†µì‹ 
â”‚   â”œâ”€â”€ nano_banana.py          # Gemini API
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â””â”€â”€ page.tsx            # ë©”ì¸ UI
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ CharacterCreator.tsx
â”‚   â”‚   â”œâ”€â”€ SceneBuilder.tsx
â”‚   â”‚   â””â”€â”€ VideoPreview.tsx
â”‚   â””â”€â”€ types/
â”‚       â””â”€â”€ index.ts
â”œâ”€â”€ comfyui/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ svd_loop.json       # ë£¨í”„ ì›Œí¬í”Œë¡œìš°
â”‚       â””â”€â”€ svd_story.json      # ìŠ¤í† ë¦¬ ì›Œí¬í”Œë¡œìš°
â”œâ”€â”€ outputs/                    # ìƒì„±ëœ ê²°ê³¼ë¬¼
â”‚   â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ videos/
â”‚   â””â”€â”€ audio/
â””â”€â”€ README.md
```

## API ì—”ë“œí¬ì¸íŠ¸

### POST /api/create-character-animation
```json
{
  "character": {
    "name": "ë‚˜ë‚˜",
    "base_description": "ë¶„í™ìƒ‰ ë¨¸ë¦¬ì˜ ì†Œë…€",
    "reference_image": "base64..."
  },
  "scenes": [
    {
      "action": "ê±·ê¸°",
      "angle": "ì •ë©´",
      "background": "ê³µì›"
    }
  ],
  "video_type": "story",
  "fps": 8,
  "frames": 25
}
```

### Response
```json
{
  "success": true,
  "character_name": "ë‚˜ë‚˜",
  "images": [...],
  "videos": [...],
  "audio": [...]
}
```

## ë¼ì´ì„ ìŠ¤ ë° í¬ë ˆë”§

- Gemini 2.5 Flash Image (Google)
- Stable Video Diffusion (Stability AI)
- ComfyUI (comfyanonymous)
- Next.js (Vercel)
- FastAPI (Tiangolo)




   










